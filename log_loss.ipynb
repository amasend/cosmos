{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import colors as mcolors\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing.imputation import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import plotly.offline as py\n",
    "from sklearn.preprocessing import Imputer\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data ... (to be described)\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Amadeusz\\\\Downloads\\\\all\\\\training_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata, ... (to be described)\n",
    "meta_dataset = pd.read_csv('C:\\\\Users\\\\Amadeusz\\\\Downloads\\\\all\\\\training_set_metadata.csv')\n",
    "column_names = {6: \"class_6\", 15: \"class_15\", 16: \"class_16\", 42: \"class_42\", 52: \"class_52\", 53: \"class_53\",\n",
    "                62: \"class_62\", 64: \"class_64\", 65: \"class_65\", 67: \"class_67\", 88: \"class_88\", 90: \"class_90\",\n",
    "                92: \"class_92\", 95: \"class_95\"}\n",
    "# change labels according to sample submission example\n",
    "meta_dataset[\"target\"] = list(map(lambda name: column_names[name], meta_dataset[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use imputer to search for NaN values and compute mean() values instead of them (column vise)\n",
    "mean_imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "mean_imputer = mean_imputer.fit(meta_dataset.iloc[:,:-1]) # without last target column (imputer does not recognize string data)\n",
    "imputed_meta_dataset = mean_imputer.transform(meta_dataset.iloc[:,:-1].values)\n",
    "imputed_meta_dataset = pd.DataFrame(data=imputed_meta_dataset, columns=meta_dataset.iloc[:,:-1].columns.values)\n",
    "imputed_meta_dataset[\"target\"] = meta_dataset.iloc[:,-1] # add last target column to imputed meta dataset\n",
    "# change object_id and ddf values back to int() ... imputer interprets all values as float()\n",
    "imputed_meta_dataset[\"object_id\"] = list(map(lambda val: int(val), imputed_meta_dataset[\"object_id\"]))\n",
    "imputed_meta_dataset[\"ddf\"] = list(map(lambda val: int(val), imputed_meta_dataset[\"ddf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_meta_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges two datasets, merge by group_id -> common key in both DataFrames\n",
    "training_dataset = pd.merge(dataset, imputed_meta_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if training_dataset consists of any empty values\n",
    "columns_missing = [col for col in training_dataset.columns if training_dataset[col].isnull().any()]\n",
    "if columns_missing:\n",
    "    print(\"Dataset has missing values in the following columns:\\n{}\".format(columns_missing))\n",
    "else:\n",
    "    print(\"Dataset do not has any column with empty value.\")\n",
    "\n",
    "# split data into training and test datasets (X and Y) ... data is randomly chosen\n",
    "test_size = 0.2\n",
    "seed = 7\n",
    "# description\n",
    "# train_test_split(X,Y,test_size,random_state)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(training_dataset.iloc[:,:-1], training_dataset.iloc[:,-1], \n",
    "                                                    test_size=test_size, random_state=seed)\n",
    "X_train = pd.DataFrame(data=X_train, columns=training_dataset.columns.values.tolist()[:-1])\n",
    "X_test = pd.DataFrame(data=X_test, columns=training_dataset.columns.values.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "et = ExtraTreesClassifier(n_estimators=100)\n",
    "# .iloc[:,1:].values (removes object_id zolumn from computing)\n",
    "et.fit(X_train.iloc[:,1:].values, Y_train)\n",
    "end = time.time()\n",
    "# accuracy score is not valid here ... accuracy means if we predict label correctly it is very good,\n",
    "# but not enough big predictions for other labels are ignored\n",
    "print(\"Extra Trees Elapsed Training time: {}   ---   Training accuracy score: {}\".format(end - start, et.score(X_train.iloc[:,1:].values, Y_train)))\n",
    "start = time.time()\n",
    "predictions = et.predict(X_test.iloc[:,1:].values)\n",
    "end = time.time()\n",
    "print(\"Extra Trees Elapsed Test prediction time: {}   ---   Testing accuracy score: {}\".format(end - start, accuracy_score(Y_test, predictions)))\n",
    "# compute predictions for each class for each row (sample)\n",
    "start = time.time()\n",
    "predicted_et = pd.DataFrame(et.predict_proba(X_test.iloc[:,1:].values), columns=et.classes_)\n",
    "end = time.time()\n",
    "print(\"Predict_proba computed in: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicted_et.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log loss function example of perfect prediction\n",
    "                                                 #0,1,2,3,4,5\n",
    "# log_loss(np.array([1,0,2,3,3,4,5,5]),np.array([[0,1,0,0,0,0],\n",
    "#                                                [1,0,0,0,0,0],\n",
    "#                                                [0,0,1,0,0,0],\n",
    "#                                                [0,0,0,1,0,0],\n",
    "#                                                [0,0,0,1,0,0],\n",
    "#                                                [0,0,0,0,1,0],\n",
    "#                                                [0,0,0,0,0,1],\n",
    "#                                                [0,0,0,0,0,1]]))\n",
    "#First argument is list of known labels, there will be comparison between them and our prediction\n",
    "#Second argument is matrix of our predictions (rows - each sumple) (columns - each label class alphabeticall sorted)\n",
    "#The return value of log loss is the measure how big distribution crossentropy is between perfect prediciton and the case,\n",
    "#smaller value means better result\n",
    "\n",
    "#To ilustrate this value more clear, exp(-log_loss) can be computed\n",
    "#This means how close we are to the perfect prediction in percentage 0-1 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "loss = log_loss(y_true=Y_test, y_pred=predicted_et.values, labels=predicted_et.columns.values.tolist())\n",
    "print(\"Log_loss: {}\".format(loss))\n",
    "print(\"Precision: {}\".format(np.exp(-loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "scaler = StandardScaler()\n",
    "X_transformed = scaler.fit_transform(X_train.iloc[:,1:].values)\n",
    "end = time.time()\n",
    "print(\"after transformation: {}\".format(end-start))\n",
    "\n",
    "# start = time.time()\n",
    "# lof = LocalOutlierFactor(novelty=True)\n",
    "# lof.fit(X_transformed)\n",
    "# end = time.time()\n",
    "# print(\"after fit: {}\".format(end-start))\n",
    "\n",
    "from sklearn import svm\n",
    "start = time.time()\n",
    "# clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1, cache_size=1000)\n",
    "clf = svm.OneClassSVM(cache_size=1000)\n",
    "clf.fit(np.ascontiguousarray(X_transformed)) #data array should be contigouss to avoid copying\n",
    "end = time.time()\n",
    "print(\"after OCSVM fit: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save model\n",
    "filename = '..\\\\OCSVM.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "x = clf.predict(X_transformed)\n",
    "end = time.time()\n",
    "print(\"after predict: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyNomaly import loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = loop.LocalOutlierProbability(X_train.iloc[:,1:].values).fit()\n",
    "scores_noclust = m.local_outlier_probabilities\n",
    "\n",
    "iriX_trains['scores'] = scores_noclust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
